{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd6f9dae-7a17-4aff-9a80-f166e60cd133",
   "metadata": {},
   "source": [
    "# AL Documentation\n",
    "\n",
    "## Introduction\n",
    "\n",
    "AL simplifies the complexity of large language models into a simple, open-source solution. One intuitive interface. Multiple AI powerhouses. Ollama, Anthropic, OpenAI - seamlessly integrated into all python environments, you can use it even on 1970 terminals if youd like that sort of a thing.\n",
    "AL doesn't just fetch answers; it preserves your learning journey. Every interaction, every spark of inspiration, is captured in Jupyter notebooks. Share, version, and automate your AI workflows with ease.\n",
    "\n",
    "But here's the game-changer: these saved sessions aren't mere logs. They're goldmines for AI advancement. Use them to fine-tune models, iterate rapidly, and fuel your learning. Reuse, edit, and evolve your AI interactions effortlessly.\n",
    "* simple ASCII/md interface\n",
    "* model selection\n",
    "* save/load history as .ipynb file\n",
    "\n",
    "## Why Use AL?\n",
    "\n",
    "AL offers several advantages over other similar tools:\n",
    "\n",
    "1. **Unified Interface**: AL provides a consistent interface for interacting with different AI models, simplifying the process of switching between or comparing various AI services.\n",
    "\n",
    "2. **Extensibility**: The base class is designed to be easily extended, allowing developers to add support for new AI services by creating subclasses.\n",
    "\n",
    "3. **History Management**: AL includes built-in conversation history management, making it easy to maintain context in multi-turn conversations.\n",
    "\n",
    "4. **Code Handling**: The class includes methods for managing and setting code snippets to the clipboard, which is particularly useful for programming-related tasks.\n",
    "\n",
    "5. **Jupyter Notebook Integration**: AL supports saving and loading conversation history in Jupyter Notebook format, facilitating easy documentation and sharing of AI interactions.\n",
    "\n",
    "## AL Class Overview\n",
    "\n",
    "1. The `AL` class serves as the foundation for AI model interactions. Here's an overview of its main components:\n",
    "\n",
    "```python\n",
    "class AL:\n",
    "    def __init__(self, interface: Literal[\"ollama\", \"claude\", \"chatgpt\"] = \"ollama\", model: str = \"llama3.1\", api_key: Optional[str] = None):\n",
    "    # implementation\n",
    "\n",
    "    def ask(self, question):\n",
    "    # implementation\n",
    "```\n",
    "\n",
    "2. To acess the code snipets from the answer:\n",
    "```python\n",
    "    def copy_code(def copy_code(self, index: Optional[int] = None):\n",
    "        # If no index then last code snippet is copied, otherwise the index runs from last to first\n",
    "```\n",
    "\n",
    "3. To store/edit as jupyter lab workbook\n",
    "```python\n",
    "        \n",
    "    def save_history(self, filename):\n",
    "        # Implementation for saving history to a Jupyter Notebook\n",
    "\n",
    "    def load_history(self, filename):\n",
    "        # Implementation for loading history from a Jupyter Notebook\n",
    "```\n",
    "## Conclusion\n",
    "\n",
    "AL provides a powerful and flexible foundation for interacting with various AI language models. By using AL, developers can easily integrate different AI services into their projects, manage conversation history, and handle code snippets efficiently. The extensible nature of AL allows for easy addition of new AI services, making it a valuable tool for developers working with multiple AI platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622d99f4-7139-41c3-8406-89c56e5455e7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Generic AL object definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fb60b6f-2e7c-4f9a-b363-c12815b195e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Optional, List, Dict\n",
    "from IPython.display import Markdown\n",
    "from datetime import datetime\n",
    "import json\n",
    "import nbformat as nbf\n",
    "import pyperclip\n",
    "\n",
    "class AL:\n",
    "    def __init__(\n",
    "        self, \n",
    "        interface: Literal[\"ollama\", \"claude\", \"chatgpt\"] = \"ollama\",\n",
    "        model: str = \"llama3.1\",\n",
    "        api_key: Optional[str] = None,\n",
    "        ollama_host: Optional[str] = None\n",
    "    ):\n",
    "        self.interface = interface\n",
    "        self.model = model\n",
    "        self.api_key = api_key\n",
    "        self.ollama_host = ollama_host  # Store the Ollama host\n",
    "        self.history = []\n",
    "        self.last_code = []\n",
    "        self.active_code = 0\n",
    "        \n",
    "        # Initialize appropriate client\n",
    "        self._init_client()\n",
    "\n",
    "    def _init_client(self):\n",
    "        if self.interface == \"ollama\":\n",
    "            import ollama\n",
    "            if self.ollama_host:\n",
    "                ollama.set_host(self.ollama_host)  # Set custom Ollama host if provided\n",
    "            self.client = ollama\n",
    "        elif self.interface == \"claude\":\n",
    "            from anthropic import Anthropic\n",
    "            self.client = Anthropic(api_key=self.api_key)\n",
    "        else:  # chatgpt\n",
    "            import openai\n",
    "            self.client = openai.OpenAI(api_key=self.api_key)\n",
    "\n",
    "    def split_response(self, response: str) -> List[Dict]:\n",
    "        segments = []\n",
    "        parts = response.split('```')\n",
    "        \n",
    "        for i, part in enumerate(parts):\n",
    "            if i % 2 == 0:\n",
    "                if part.strip():\n",
    "                    segments.append({\n",
    "                        \"type\": \"markdown\", \n",
    "                        \"content\": part.strip()\n",
    "                    })\n",
    "            else:\n",
    "                lines = part.splitlines()\n",
    "                if lines:\n",
    "                    language = lines[0].strip()\n",
    "                    code = '\\n'.join(lines[1:])\n",
    "                    self.last_code.insert(0, code.strip())\n",
    "                    segments.append({\n",
    "                        \"type\": \"code\", \n",
    "                        \"language\": language, \n",
    "                        \"content\": code.strip()\n",
    "                    })\n",
    "        \n",
    "        return segments\n",
    "\n",
    "    def ask(self, message: str):\n",
    "        # Store user message\n",
    "        self.history.append({\n",
    "            \"role\": \"human\",\n",
    "            \"content\": message,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "        # Get response based on interface\n",
    "        response = self._get_response(message)\n",
    "        \n",
    "        # Process and store response\n",
    "        self.history.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": response,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "        # Display response\n",
    "        segments = self.split_response(response)\n",
    "        for segment in segments:\n",
    "            if segment['type'] == 'markdown':\n",
    "                display(Markdown(segment['content']))\n",
    "            else:\n",
    "                print(f\"```{segment['language']}\\n{segment['content']}\\n```\")\n",
    "        \n",
    "    # get last answer as string\n",
    "\n",
    "    def _get_response(self, message: str) -> str:\n",
    "        if self.interface == \"ollama\":\n",
    "            response = self.client.chat(\n",
    "                model=self.model, \n",
    "                messages=[{\"role\": \"user\", \"content\": message}]\n",
    "            )\n",
    "            return response['message']['content']\n",
    "        elif self.interface == \"claude\":\n",
    "            response = self.client.messages.create(\n",
    "                model=self.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": message}]\n",
    "            )\n",
    "            return response.content[0].text\n",
    "        else:  # chatgpt\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": message}]\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "\n",
    "    def copy_code(self, index: Optional[int] = None):\n",
    "        \"\"\"Copy specific code block to clipboard\"\"\"\n",
    "        if index is None:\n",
    "            index = self.active_code\n",
    "        if 0 <= index < len(self.last_code):\n",
    "            pyperclip.copy(self.last_code[index])\n",
    "            print(f\"Copied code block {index} to clipboard\")\n",
    "        else:\n",
    "            print(\"Invalid code block index\")\n",
    "\n",
    "    def save_history(self, filename: str):\n",
    "        \"\"\"Save conversation to notebook\"\"\"\n",
    "        if not filename.endswith('.ipynb'):\n",
    "            filename += '.ipynb'\n",
    "            \n",
    "        nb = nbf.v4.new_notebook()\n",
    "        cells = []\n",
    "\n",
    "        for entry in self.history:\n",
    "            # Add role cell\n",
    "            cells.append(nbf.v4.new_markdown_cell(\n",
    "                f\"## {entry['role'].capitalize()}\"\n",
    "            ))\n",
    "\n",
    "            # Split and add content cells\n",
    "            segments = self.split_response(entry['content'])\n",
    "            for segment in segments:\n",
    "                if segment['type'] == 'markdown':\n",
    "                    cells.append(nbf.v4.new_markdown_cell(\n",
    "                        segment['content']\n",
    "                    ))\n",
    "                else:\n",
    "                    cells.append(nbf.v4.new_code_cell(\n",
    "                        segment['content']\n",
    "                    ))\n",
    "\n",
    "        nb['cells'] = cells\n",
    "        \n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            nbf.write(nb, f)\n",
    "\n",
    "    def load_history(self, filename: str):\n",
    "        \"\"\"Load conversation from notebook\"\"\"\n",
    "        if not filename.endswith('.ipynb'):\n",
    "            filename += '.ipynb'\n",
    "            \n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            nb = nbf.read(f, as_version=4)\n",
    "        \n",
    "        self.history = []\n",
    "        self.last_code = []\n",
    "        \n",
    "        current_entry = None\n",
    "        \n",
    "        for cell in nb.cells:\n",
    "            source = cell['source']\n",
    "            \n",
    "            if cell['cell_type'] == 'markdown' and source.startswith('## '):\n",
    "                # If we have a previous entry, add it\n",
    "                if current_entry:\n",
    "                    self.history.append(current_entry)\n",
    "                \n",
    "                # Start new entry\n",
    "                role = source[3:].lower().strip()\n",
    "                current_entry = {\n",
    "                    'role': role,\n",
    "                    'content': '',\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "            elif current_entry:\n",
    "                # Add content to current entry\n",
    "                if cell['cell_type'] == 'code':\n",
    "                    self.last_code.append(source)\n",
    "                    current_entry['content'] += f'```python\\n{source}\\n```\\n'\n",
    "                else:\n",
    "                    current_entry['content'] += f'{source}\\n'\n",
    "        \n",
    "        # Add last entry if exists\n",
    "        if current_entry:\n",
    "            self.history.append(current_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb69c4e3-0082-49bd-bf57-0fb3bb2ee9bd",
   "metadata": {},
   "source": [
    "# Testing and ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07277d0c-8f2f-4fdf-9414-e87f21d19976",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = AL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe94a31b-8d04-4be3-98f2-217127159a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is a simple implementation of a Random Number Generator (RNG) in Python:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import secrets\n",
      "\n",
      "class RNG:\n",
      "    def __init__(self, seed=None):\n",
      "        if seed is not None:\n",
      "            self.seed = seed\n",
      "        else:\n",
      "            self.seed = secrets.randbelow(2**32)\n",
      "\n",
      "    def random(self):\n",
      "        return self.seed * 1103515245 + 12345 >> 16\n",
      "\n",
      "\n",
      "# Example usage:\n",
      "\n",
      "rng = RNG(seed=42)\n",
      "print(rng.random())  # Output: a random number between 0 and 32767\n",
      "\n",
      "for _ in range(10):\n",
      "    print(rng.random())\n",
      "```\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "However, the above implementation is not cryptographically secure. For security-critical applications (like password generation or cryptographic protocols), you should use the `secrets` module from Python's standard library:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import secrets\n",
      "\n",
      "def rng():\n",
      "    return secrets.randbelow(2**32)\n",
      "\n",
      "\n",
      "# Example usage:\n",
      "\n",
      "print(rng())  # Output: a random number between 0 and 4294967295\n",
      "```\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The `secrets` module is designed to generate cryptographically strong random numbers suitable for managing data such as passwords, account authentication, security tokens, and related secrets."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat.ask(\"can you write simple random number generator in python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7158de5-2ab1-4530-abbe-6c46bb521b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied code block 1 to clipboard\n"
     ]
    }
   ],
   "source": [
    "chat.copy_code(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a951bdd9-f696-4fbd-9fb9-44f09a90be3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random number: 92\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generate_random_number(min_val, max_val):\n",
    "    \"\"\"\n",
    "    Generate a random integer between min_val and max_val.\n",
    "\n",
    "    Args:\n",
    "        min_val (int): The minimum value to generate.\n",
    "        max_val (int): The maximum value to generate.\n",
    "\n",
    "    Returns:\n",
    "        int: A random integer between min_val and max_val.\n",
    "    \"\"\"\n",
    "    return random.randint(min_val, max_val)\n",
    "\n",
    "# Example usage\n",
    "random_num = generate_random_number(1, 100)\n",
    "print(f\"Random number: {random_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56b34e85-2811-4e1e-bb12-bcbe9496fc7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class SimpleRNG:\\n    def __init__(self, seed):\\n        self.seed = seed\\n\\n    def generate_random_number(self, min_val, max_val):\\n        \"\"\"\\n        Generate a random integer between min_val and max_val.\\n\\n        Args:\\n            min_val (int): The minimum value to generate.\\n            max_val (int): The maximum value to generate.\\n\\n        Returns:\\n            int: A random integer between min_val and max_val.\\n        \"\"\"\\n        self.seed = (1103515245 * self.seed + 12345) % 2**31\\n        return min_val + (max_val - min_val) * (self.seed // (2**31))\\n\\n# Example usage\\nrng = SimpleRNG(42)\\nrandom_num = rng.generate_random_number(1, 100)\\nprint(f\"Random number: {random_num}\")'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.last_code[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba4df76-32d7-47fa-9db9-35d6b19b5c88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
