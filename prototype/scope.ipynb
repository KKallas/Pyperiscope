{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51dca4a8-e4cd-4c20-b68a-9c7c45af2257",
   "metadata": {},
   "source": [
    "# Scope\n",
    "Visual Automation System for Jupyter Lab\n",
    "\n",
    "## Overview\n",
    "\n",
    "A comprehensive framework for GUI automation that enables precise screen element detection, pattern matching, and interaction. Scope provides tools for capturing, processing, and detecting visual elements on screen with configurable parameters and robust error handling.\n",
    "\n",
    "## Usage\n",
    "### 1. Create Scope\n",
    "```python\n",
    "scope = Scope(mouse_offset=(100, 100), crop_size=(640, 480), area_offset=(50, 50), area_size=(64, 64))\n",
    "```\n",
    "\n",
    "### 2. Find on screen and click\n",
    "```python\n",
    "scope.find(tries=1, timeout=1, confidence=0.9)\n",
    "if scope.found_locations:\n",
    "    pyautogui.click(scope.get_locations()[0])\n",
    "```\n",
    "\n",
    "### 3. Save as b64 string\n",
    "```python\n",
    "scope.save_string() #Use it in sepparate jupyter cell to convert the cell into b64 string and object deffinition\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad87ed6c-6357-4e9f-980b-026a7b83d5c8",
   "metadata": {},
   "source": [
    "Scope Base\n",
    "=======================\n",
    "[layer1](../src/pyperiscope/scope/layer1.py)\n",
    "\n",
    "The `Scope` class is designed for capturing and processing screenshots using Python's `pyautogui` and image manipulation libraries. It allows users to capture a portion of their screen, define specific areas of interest, and save or load these areas as base64-encoded images. Below is an overview of how to use the class.\n",
    "\n",
    "Initialization\n",
    "--------------\n",
    "\n",
    "To initialize the `Scope` class:\n",
    "\n",
    "```python\n",
    "scope = Scope(mouse_offset=(100, 100), crop_size=(640, 480), area_offset=(50, 50), area_size=(64, 64))\n",
    "```\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "*   `mouse_offset`: Tuple of x, y coordinates for the mouse position offset.\n",
    "*   `crop_size`: The dimensions of the captured cropped area.\n",
    "*   `area_offset`: The offset for the smaller focus area relative to the cursor.\n",
    "*   `area_size`: The size of the area of interest for finer control.\n",
    "*   `cursor_size`: Size of the cursor for alignment.\n",
    "\n",
    "Saving the Data\n",
    "---------------\n",
    "\n",
    "You can save the captured images and metadata in a dictionary using `save_dict()`:\n",
    "\n",
    "```python\n",
    "data = scope.save_dict()\n",
    "```\n",
    "\n",
    "This returns a dictionary containing base64-encoded images and metadata of the screen.\n",
    "\n",
    "Loading Saved Data\n",
    "------------------\n",
    "\n",
    "To reload the saved screenshot and area data, use:\n",
    "\n",
    "```python\n",
    "scope.load_from_dict(saved_dict)\n",
    "```\n",
    "\n",
    "This restores the screen capture and focus area from previously saved data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b874dc9-3f8e-4fa9-8dab-c9771fc555bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "class Scope:\n",
    "    def __init__(self, saved_dict=None, saved_image=None, mouse_offset=(0, 0), area_offset=(0,0),\n",
    "                 crop_size=(640, 640), area_size=(64, 64), cursor_size=32, crop_offset=(0,0)):\n",
    "        self.crop_size = tuple(max(size, 640) for size in crop_size)\n",
    "        self.area_size = tuple(max(size, 32) for size in area_size)\n",
    "        self.area_offset = area_offset\n",
    "        self.mouse_offset = tuple(max(offset, 0) for offset in mouse_offset)\n",
    "        self.cursor_size = cursor_size\n",
    "        self.crop_offset = crop_offset\n",
    "        self.found_locations = []\n",
    "        \n",
    "        if saved_dict:\n",
    "            self.load_from_dict(saved_dict)\n",
    "            return\n",
    "        if saved_image:\n",
    "            self.full_image = saved_image\n",
    "            self.full_size = saved_image.size\n",
    "            self.update_crop_and_area()\n",
    "            return\n",
    "            \n",
    "        self.initial_capture()\n",
    "\n",
    "    def initial_capture(self):\n",
    "        self.full_image = pyautogui.screenshot()\n",
    "        self.full_size = self.full_image.size\n",
    "        self.update_crop_and_area()\n",
    "\n",
    "    def update_crop_and_area(self, full_image = None):\n",
    "        full_screen_image = full_image or self.full_image.copy()\n",
    "        crop_x = min(max((self.mouse_offset[0] + self.crop_offset[0]) - self.crop_size[0] // 2, 0), self.full_size[0] - self.crop_size[0])\n",
    "        crop_y = min(max((self.mouse_offset[1] + self.crop_offset[1]) - self.crop_size[1] // 2, 0), self.full_size[1] - self.crop_size[1])\n",
    "        self.crop_box = (crop_x, crop_y, crop_x + self.crop_size[0], crop_y + self.crop_size[1])\n",
    "\n",
    "        area_x = self.mouse_offset[0] + self.area_offset[0]\n",
    "        area_y = self.mouse_offset[1] + self.area_offset[1]\n",
    "        self.area_box = (area_x, area_y, area_x + self.area_size[0], area_y + self.area_size[1])\n",
    "\n",
    "        self.cropped_image = full_screen_image.copy().crop(self.crop_box)\n",
    "        \n",
    "        area_box_clipped = (\n",
    "            max(0, self.area_box[0]),\n",
    "            max(0, self.area_box[1]),\n",
    "            min(self.full_size[0], self.area_box[2]),\n",
    "            min(self.full_size[1], self.area_box[3])\n",
    "        )\n",
    "        \n",
    "        self.area_image = full_screen_image.copy().crop(area_box_clipped)\n",
    "\n",
    "    def encode_image(self, image):\n",
    "        buffer = BytesIO()\n",
    "        image.save(buffer, format=\"PNG\")\n",
    "        return base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "\n",
    "    def save_dict(self):\n",
    "        output_dict = {\n",
    "            'area': self.encode_image(self.area_image),\n",
    "            'clean_preview': self.encode_image(self.cropped_image),\n",
    "            'image_metadata': {\n",
    "                'area_box': self.area_box,\n",
    "                'area_offset': self.area_offset,\n",
    "                'area_size': self.area_size, \n",
    "                'crop_box': self.crop_box, \n",
    "                'crop_size': self.crop_size,\n",
    "                'cursor_size': self.cursor_size,\n",
    "                'image_size': self.full_size,\n",
    "                'mouse_offset': self.mouse_offset\n",
    "            }}\n",
    "        return output_dict\n",
    "\n",
    "    def load_from_dict(self, saved_dict):\n",
    "        self.area_image = Image.fromarray(np.array(Image.open(BytesIO(base64.b64decode(saved_dict['area'])))), mode=\"RGB\")\n",
    "        self.cropped_image = Image.fromarray(np.array(Image.open(BytesIO(base64.b64decode(saved_dict['clean_preview'])))), mode=\"RGB\")\n",
    "        metadata = saved_dict['image_metadata']\n",
    "        #for attr in ['area_box', 'area_offset', 'area_size', 'crop_box', 'crop_size', 'cursor_size', 'image_size', 'mouse_offset']:\n",
    "        #    setattr(self, attr, tuple(metadata[attr]))\n",
    "        self.area_box = metadata['area_box']\n",
    "        self.area_offset = metadata['area_offset']\n",
    "        self.area_size = metadata['area_size']\n",
    "        self.crop_box = metadata['crop_box']\n",
    "        self.crop_size = metadata['crop_size']\n",
    "        self.cursor_size = metadata['cursor_size']\n",
    "        self.full_size = metadata['image_size']\n",
    "        self.mouse_offset = metadata['mouse_offset']\n",
    "        # Generate black image in the original desktop size and add only the caprured preview in the right location\n",
    "        self.full_size = tuple(metadata['image_size'])\n",
    "        full_image = Image.new('RGB', self.full_size, color='black')\n",
    "        full_image.paste(self.cropped_image, self.crop_box[:2])\n",
    "        self.full_image = full_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14201292-cad8-48de-9095-9107f734ec3f",
   "metadata": {},
   "source": [
    "Scope UI Extension Usage Guide\n",
    "=================================\n",
    "[layer2](../src/pyperiscope/scope/layer2.py)\n",
    "\n",
    "This extended `Scope` class builds on the base `Scope` class, introducing methods to render a visual preview of captured areas and mark specific locations on the screen capture. These enhancements allow for annotated and labeled screenshots, highlighting areas of interest.\n",
    "\n",
    "\n",
    "Rendering a Preview\n",
    "-------------------\n",
    "\n",
    "The `render_preview()` method renders the preview of the screen with annotations such as highlighted areas and labels. It can either return the full screen or a cropped version.\n",
    "\n",
    "### Usage:\n",
    "\n",
    "```python\n",
    "preview_image = scope.render_preview(marker={'area': (100, 150, 200, 250), 'mouse_offset': (120, 130), 'label': 'Highlight'})\n",
    "```\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "*   `base_image`: (Optional) Provide a custom image to overlay the preview on, otherwise uses `self.full_image`.\n",
    "*   `marker`: Dictionary with keys:\n",
    "    *   `area`: Coordinates of the area to highlight.\n",
    "    *   `mouse_offset`: Cursor position for crosshair rendering.\n",
    "    *   `label`: Label text for the highlighted area.\n",
    "*   `cropped`: If `True`, returns the cropped image, otherwise returns the full image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "e0919ba9-5e10-47ba-84fc-d0df521350a2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Scope(Scope):\n",
    "    def render_preview(self, base_image=None, marker=None, cropped=True):\n",
    "        preview = base_image or self.full_image\n",
    "        if marker:\n",
    "            area = marker['area']\n",
    "            mouse_offset = marker['mouse_offset']\n",
    "            label_text = marker['label']\n",
    "        else:\n",
    "            area = self.area_box\n",
    "            mouse_offset = self.mouse_offset\n",
    "            label_text = 'set area:'\n",
    "        preview = preview.copy()\n",
    "        area = (area[0], area[2], area[1], area[3])\n",
    "        draw = ImageDraw.Draw(preview, 'RGBA')\n",
    "        \n",
    "        draw.rectangle((area[0],area[2],area[1],area[3]), fill=(255, 165, 0, 128), outline=(255, 0, 0), width=2)\n",
    "        self.draw_label(draw, (area[0],area[2],area[1],area[3]), label_text, self.cursor_size)\n",
    "        self.draw_mouse_location(draw, mouse_offset, self.cursor_size)\n",
    "        if cropped:\n",
    "            return preview.crop(self.crop_box)       \n",
    "        else:\n",
    "            return preview\n",
    "    \n",
    "    def draw_mouse_location(self, draw, mouse_offset, cursor_size):\n",
    "        # Draw the location cross\n",
    "        draw.line(((mouse_offset[0] - cursor_size // 2, mouse_offset[1]),(mouse_offset[0] + cursor_size // 2, mouse_offset[1])), fill=(0, 255, 255), width=2)\n",
    "        draw.line(((mouse_offset[0], mouse_offset[1] - cursor_size // 2),(mouse_offset[0], mouse_offset[1] + cursor_size // 2)), fill=(0, 255, 255), width=2)\n",
    "        \n",
    "    def draw_label(self, draw, area, label_text, cursor_size):\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"arialbd.ttf\", cursor_size // 2 - 2)\n",
    "        except IOError:\n",
    "            font = ImageFont.load_default()\n",
    "        \n",
    "        label_text = label_text.upper()\n",
    "        label_bbox = draw.textbbox((0, 0), label_text, font=font)\n",
    "        \n",
    "        label_position = (area[0] + 5, area[1] + 1)  # 5 pixels offset from the top-left corner\n",
    "        label_bg = (label_position[0] - 5, label_position[1], label_position[0] + (label_bbox[2] - label_bbox[0]) + 6, label_position[1] + (label_bbox[3] - label_bbox[1]) + 6)\n",
    "        draw.rectangle(label_bg, fill=(255, 0, 0))  # Red background\n",
    "        \n",
    "        # Draw label text\n",
    "        draw.text(label_position, label_text, fill=(255, 255, 255), font=font) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f11bcc2-e4d8-4aa5-bfed-300fc60df233",
   "metadata": {},
   "source": [
    "Make the object sharable as plain text\n",
    "=================================\n",
    "[layer3](../src/pyperiscope/scope/layer3.py)\n",
    "\n",
    "Scope extension to add DataBoomer output with save_string command\n",
    "\n",
    "It will turn the cell where it is ran into deffinition of an automation step, then you can copy this and use it in Automation workbook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c27880-a719-4598-aa56-72e39b1fab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elvis_repl import elvis\n",
    "from databoomer import DataBoomer\n",
    "from string import Template\n",
    "\n",
    "class Scope(Scope):\n",
    "    def get_string(self):\n",
    "        new_template = Template(\"# comment: Automated step generated with pyPeriscope V2 $comment\\npayload = \\'\\'\\'$payload\\'\\'\\'\\n$obj_name = Scope(saved_dict=dill.loads(codecs.decode(payload.encode(), 'base64')))\\nstep.render_preview()\")\n",
    "        db = DataBoomer(self.save_dict(), obj_name = \"step\", template = new_template)\n",
    "        return (db.payload)\n",
    "    def save_string(self):\n",
    "        e = elvis(\"{s}\", s=self.get_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6734013b-3a6c-43eb-b085-94a959673e3b",
   "metadata": {},
   "source": [
    "Scope Find and Draw Class Extension Usage Guide\n",
    "===============================================\n",
    "[layer4](../src/pyperiscope/scope/layer4.py)\n",
    "\n",
    "This extension to the `Scope` class adds functionality for detecting and marking patterns on the screen. It uses `pyautogui` to search for instances of a specific area of interest (`area_image`) within the screen and highlights these occurrences. Additionally, it provides methods to render the found locations on the captured screen.\n",
    "\n",
    "Pattern Detection\n",
    "-----------------\n",
    "The `find()` method identifies all occurrences of the predefined `area_image` on the screen with configurable retry attempts and confidence threshold.\n",
    "\n",
    "### Parameters:\n",
    "```python\n",
    "scope.find(tries=1, timeout=1, confidence=0.9)\n",
    "```\n",
    "- `tries`: Number of attempts to locate the pattern (default: 1)\n",
    "- `timeout`: Delay in seconds between retry attempts (default: 1)\n",
    "- `confidence`: Pattern matching threshold from 0 to 1 (default: 0.9)\n",
    "\n",
    "### Retry Logic:\n",
    "The method implements a robust retry mechanism to handle temporary screen state changes or pattern visibility issues:\n",
    "\n",
    "1. Takes a screenshot of the current screen\n",
    "2. Attempts to locate all pattern matches with the specified confidence level\n",
    "3. If the attempt fails, waits for the timeout period and retries\n",
    "4. Continues until either:\n",
    "   - Pattern(s) are successfully found\n",
    "   - Maximum number of tries is reached\n",
    "4. Prints progress (\"try: X/Y\") during retries\n",
    "5. Raises the last encountered exception if all attempts fail\n",
    "\n",
    "### Pattern Processing:\n",
    "For each detected pattern, the method:\n",
    "\n",
    "1. Creates location metadata including:\n",
    "   - Bounding box coordinates\n",
    "   - Mouse offset for interaction\n",
    "   - Numeric label (\"[0] STEP\", \"[1] STEP\", etc.)\n",
    "2. Validates against existing locations using `overlap()` to prevent duplicates\n",
    "3. Increments the pattern counter for unique finds\n",
    "4. Stores valid locations for later rendering\n",
    "\n",
    "The final count of unique patterns is printed upon completion (\"found: X\").\n",
    "\n",
    "Drawing Detected Patterns\n",
    "-------------------------\n",
    "Once patterns are detected, the `draw_found()` method renders all found locations onto the screenshot. Each occurrence is labeled and marked on the screen, allowing users to visually identify the detected areas.\n",
    "\n",
    "### Usage:\n",
    "```python\n",
    "found_image = scope.draw_found(found_id=0)\n",
    "found_image.show()\n",
    "```\n",
    "\n",
    "### Parameters:\n",
    "- `found_id`: Index of the found location to render. Defaults to `0`, which is the first found location.\n",
    "\n",
    "### How It Works:\n",
    "- The base screenshot is used to overlay detected patterns\n",
    "- The method calls `render_preview()` to draw the label and highlight each found location\n",
    "- The final image can be cropped to the original area defined by `self.crop_box`\n",
    "    \n",
    "Output and Display\n",
    "------------------\n",
    "The `draw_found()` method generates an annotated screenshot with all found patterns highlighted. You can crop the image or display it using Pillow's `Image.show()` method, or save it for further analysis.\n",
    "\n",
    "This extension is especially useful in automating the process of detecting patterns on the screen and providing clear visual feedback on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "99912f44-97b5-4988-90f5-a97ff8784067",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scope(Scope):\n",
    "    def find(self, tries=1, timeout=1, confidence=0.9):\n",
    "        count = 1\n",
    "        self.found_locations = []\n",
    "        self.found_image = pyautogui.screenshot()\n",
    "\n",
    "        for i in range(tries):\n",
    "            try:\n",
    "                found_patterns = pyautogui.locateAllOnScreen(self.area_image, confidence=confidence)\n",
    "                for loc in found_patterns:\n",
    "                    new_loc = {'area':(loc.left, loc.top, loc.left + self.area_size[0], loc.top + self.area_size[1]),\n",
    "                                                 'mouse_offset':(loc.left - self.area_offset[0], loc.top - self.area_offset[1]), \n",
    "                                                 'label':\"[0] STEP\", \n",
    "                                                 'area_offset':self.area_offset}\n",
    "        \n",
    "                    if self.found_locations == []: \n",
    "                        self.found_locations.append(new_loc)\n",
    "                        continue\n",
    "        \n",
    "                    if not(self.overlap(self.found_locations[-1], new_loc)):\n",
    "                        new_loc['label'] = \"[\"+str(count)+\"] STEP\"\n",
    "                        self.found_locations.append(new_loc)\n",
    "                        count = count + 1\n",
    "                        continue\n",
    "                break\n",
    "            except Exception as e:\n",
    "                if i==(tries-1):\n",
    "                    raise e\n",
    "                else:\n",
    "                    time.sleep(timeout)\n",
    "                print(\"try: \" + str(i) + \"/\" + str(tries))\n",
    "\n",
    "        print(\"found: \" + str(count))\n",
    "\n",
    "    def overlap(self, area1, area2):\n",
    "        x1, y1, x2, y2 = area1['area']\n",
    "        x3, y3, x4, y4 = area2['area']\n",
    "        \n",
    "        if x3 < x2: # check X overlap\n",
    "            return True\n",
    "        if y3 < y2: # check Y overlap\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def draw_found(self, found_id=0):\n",
    "        base_image = self.found_image.copy()\n",
    "        self.mouse_offset = self.found_locations[found_id]['mouse_offset']\n",
    "        self.area_offset = self.found_locations[found_id]['area_offset']\n",
    "        self.update_crop_and_area(full_image=base_image)\n",
    "        \n",
    "        for loc in self.found_locations:\n",
    "            base_image = self.render_preview(base_image, marker=loc, cropped=False)\n",
    "\n",
    "        return base_image.crop(self.crop_box) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2062c11-b2a0-409b-9269-fcb852a91c57",
   "metadata": {},
   "source": [
    "Scope String Generator\n",
    "===============================================\n",
    "[layer5](../src/pyperiscope/scope/layer5.py)\n",
    "\n",
    "A utility method for the `Scope` class that helps generate new scope configurations from existing ones. This is particularly useful when:\n",
    "- A recorded step doesn't work and you need to create a new step from the current position\n",
    "- You want to create a new empty step while preserving parameters from an existing step\n",
    "\n",
    "## Usage\n",
    "\n",
    "### Basic Usage\n",
    "\n",
    "```python\n",
    "# Get string representation of current scope\n",
    "current_step = Scope(mouse_offset=(10, 20))\n",
    "print(current_step.generate_scope_string())\n",
    "# Output: step = Scope(mouse_offset=(10, 20))\n",
    "```\n",
    "\n",
    "### Creating New Step from Current Position\n",
    "\n",
    "If your recorded step isn't working, you can create a new one from your current position:\n",
    "\n",
    "```python\n",
    "# Create new step from current position\n",
    "new_step = Scope()  # Empty step\n",
    "current_step = Scope(area_size=(128, 128))  # Current position\n",
    "print(new_step.generate_scope_string(current_step))\n",
    "# Output: step = Scope(area_size=(128, 128))\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "The method takes one optional parameter:\n",
    "- `step` (Scope, optional): Another Scope object to use as reference. If not provided, uses the current instance.\n",
    "\n",
    "### Default Values\n",
    "\n",
    "The method compares against these default values:\n",
    "- `mouse_offset`: (0, 0)\n",
    "- `area_offset`: (0, 0)\n",
    "- `area_size`: (64, 64)\n",
    "- `crop_size`: (640, 640)\n",
    "- `cursor_size`: 32\n",
    "\n",
    "Only non-default values will be included in the output string.\n",
    "\n",
    "## Examples\n",
    "\n",
    "```python\n",
    "# Using current scope\n",
    "step1 = Scope(mouse_offset=(10, 20), area_size=(128, 128))\n",
    "print(step1.generate_scope_string())\n",
    "# Output: step = Scope(mouse_offset=(10, 20), area_size=(128, 128))\n",
    "\n",
    "# Using another scope as reference\n",
    "step2 = Scope()  # Empty step\n",
    "print(step2.generate_scope_string(step1))\n",
    "# Output: step = Scope(mouse_offset=(10, 20), area_size=(128, 128))\n",
    "\n",
    "# Using default values\n",
    "step3 = Scope()\n",
    "print(step3.generate_scope_string())\n",
    "# Output: step = Scope()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "e4348a44-339c-4b53-9afa-58550626312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scope(Scope):\n",
    "    def generate_scope_string(self, step=None):\n",
    "        \n",
    "        if step==None:\n",
    "            step=self\n",
    "        \n",
    "        defaults = {'mouse_offset': (0, 0), 'area_offset': (0, 0), 'area_size': (64, 64), 'crop_size': (640, 640), 'cursor_size': 32}\n",
    "        current_values = {'mouse_offset': step.mouse_offset, 'area_offset': step.area_offset, 'area_size': step.area_size, 'crop_size': step.crop_size, 'cursor_size': step.cursor_size}\n",
    "        \n",
    "        # Filter out values that match defaults\n",
    "        non_default = {\n",
    "            key: value for key, value in current_values.items()\n",
    "            if value != defaults[key]\n",
    "        }\n",
    "        \n",
    "        if not non_default:\n",
    "            return \"step = Scope()\"\n",
    "        \n",
    "        # Format non-default values\n",
    "        params = []\n",
    "        for key, value in non_default.items():\n",
    "            if isinstance(value, tuple):\n",
    "                formatted_value = str(value)\n",
    "            else:\n",
    "                formatted_value = str(value)\n",
    "            params.append(f\"{key}={formatted_value}\")\n",
    "        \n",
    "        return f\"step = Scope({', '.join(params)})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2297788-745a-483a-b7d6-de005a65b624",
   "metadata": {},
   "source": [
    "High DPI support\n",
    "===============================================\n",
    "[layer6](../src/pyperiscope/scope/layer6.py)\n",
    "\n",
    "to take care of high dpi screens where image resolution is higher thanpossible mouse co-ordinates like mac-os\n",
    "\n",
    "## TODO:\n",
    "- [ ] Screenshoot needs to be double size as well\n",
    "- [ ] Chnage the metadata and bas64 string format to only have full resolution area but preview is saved as half resolution jpeg in hdpi screens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dc1b1d-ec2c-41d7-ba1f-950f549bf933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "\n",
    "class Scope(Scope):\n",
    "    def get_locations(self):\n",
    "        scaled_locations = []\n",
    "        scale = pyautogui.screenshot().size[0]/pyautogui.size()[0]\n",
    "        if self.found_locations:\n",
    "            for location in self.found_locations:\n",
    "                scaled_locations.append((location['mouse_offset'][0]/scale,location['mouse_offset'][1]/scale))\n",
    "        return scaled_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e406a99-3b07-40f7-9364-55684368117f",
   "metadata": {},
   "source": [
    "# Testing and ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4275c9c1-c299-4954-b62b-6d62c5b55ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Scope(mouse_offset=(2650,420), area_offset=(-100,-100), area_size=(128,64))\n",
    "#test.find()\n",
    "#test.draw_found()\n",
    "test.render_preview()\n",
    "#test.area_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "0415296a-b188-4c6f-9f69-c7b7c0f0b6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found: 1\n"
     ]
    }
   ],
   "source": [
    "test.find()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
